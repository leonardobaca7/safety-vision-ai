# ğŸ‰ Â¡PROYECTO CONFIGURADO EXITOSAMENTE!

## âœ… Resumen de lo que hemos completado:

### 1. Repositorio Git
- âœ… Repositorio inicializado localmente
- âœ… Conectado con GitHub: https://github.com/leonardobaca7/safety-vision-ai
- âœ… Primer commit realizado
- âœ… CÃ³digo subido a GitHub

### 2. Entorno Python
- âœ… Poetry instalado (v2.3.1)
- âœ… Python 3.13.3 configurado
- âœ… Entorno virtual activo en: `C:/Users/LENOVO/OneDrive/Documentos/SISTEMASCORE/venv`

### 3. Dependencias Instaladas
**LibrerÃ­as Principales:**
- âœ… Ultralytics (YOLOv8)
- âœ… OpenCV (opencv-python-headless + opencv-python)
- âœ… FastAPI + Uvicorn
- âœ… SQLAlchemy + psycopg2-binary
- âœ… Pydantic Settings
- âœ… PyTorch 2.9.1 + Torchvision
- âœ… ONNX Runtime
- âœ… Pandas, NumPy, Pillow

**Herramientas de Desarrollo:**
- âœ… Pytest + pytest-asyncio
- âœ… Black (formateo de cÃ³digo)
- âœ… isort (ordenar imports)
- âœ… Flake8 (linting)
- âœ… Mypy (type checking)
- âœ… Pre-commit hooks
- âœ… Jupyter Notebook
- âœ… Matplotlib + Seaborn

### 4. Estructura del Proyecto
```
Safety-Vision-AI/
â”œâ”€â”€ âœ… app/                    # CÃ³digo de la aplicaciÃ³n
â”œâ”€â”€ âœ… inference_pipeline/     # Scripts de inferencia
â”œâ”€â”€ âœ… notebooks/              # Jupyter notebooks
â”œâ”€â”€ âœ… datasets/               # Para datasets
â”œâ”€â”€ âœ… models_assets/          # Para modelos
â”œâ”€â”€ âœ… docker/                 # Dockerfiles
â”œâ”€â”€ âœ… tests/                  # Tests
â”œâ”€â”€ âœ… outputs/                # Alertas y logs
â”œâ”€â”€ âœ… .env                    # ConfiguraciÃ³n (creado)
â””â”€â”€ âœ… Archivos de configuraciÃ³n
```

---

## ğŸš€ PRÃ“XIMOS PASOS: FASE 1 - Fine-Tuning del Modelo

### Paso 1: Descargar Dataset de EPP

Tienes 3 opciones principales:

#### OpciÃ³n A: Roboflow Universe (Recomendado)

1. **Ve a Roboflow Universe:**
   - URL: https://universe.roboflow.com/
   
2. **Busca uno de estos datasets:**
   - "Hard Hat Detection"
   - "Construction Safety Detection"
   - "PPE Detection"
   
3. **Descarga el dataset:**
   - Formato: **YOLOv8**
   - Descomprimir en: `datasets/helmet_vest_detection/`

**Datasets Recomendados:**

ğŸ”¥ **Hard Hat Workers Dataset** (MÃ¡s popular)
- Link: https://universe.roboflow.com/roboflow-universe-projects/hard-hat-workers
- Clases: hardhat, head, person
- ~5000+ imÃ¡genes

ğŸ”¥ **Construction Site Safety** 
- Link: https://universe.roboflow.com/mohamed-traore-2ekkp/construction-site-safety
- Clases: Hardhat, Safety Vest, NO-Hardhat, NO-Safety Vest, Person
- ~2500+ imÃ¡genes

ğŸ”¥ **PPE Detection**
- Link: https://universe.roboflow.com/ppe-detection/ppe-detection-dataset
- Clases: Hard Hat, Safety Vest, Person
- ~1500+ imÃ¡genes

#### OpciÃ³n B: Kaggle

1. **Dataset de Hard Hat:**
   - URL: https://www.kaggle.com/datasets/andrewmvd/hard-hat-detection
   - Necesitas convertir a formato YOLO si estÃ¡ en otro formato

#### OpciÃ³n C: Crear tu propio dataset (Avanzado)

- Tomar fotos/videos de trabajadores
- Anotar con Roboflow o LabelImg
- Exportar en formato YOLO

---

### Paso 2: Preparar el Dataset

Una vez descargado, tu estructura debe verse asÃ­:

```
datasets/helmet_vest_detection/
â”œâ”€â”€ train/
â”‚   â”œâ”€â”€ images/
â”‚   â”‚   â”œâ”€â”€ image1.jpg
â”‚   â”‚   â”œâ”€â”€ image2.jpg
â”‚   â”‚   â””â”€â”€ ...
â”‚   â””â”€â”€ labels/
â”‚       â”œâ”€â”€ image1.txt
â”‚       â”œâ”€â”€ image2.txt
â”‚       â””â”€â”€ ...
â”œâ”€â”€ valid/
â”‚   â”œâ”€â”€ images/
â”‚   â””â”€â”€ labels/
â”œâ”€â”€ test/ (opcional)
â”‚   â”œâ”€â”€ images/
â”‚   â””â”€â”€ labels/
â””â”€â”€ data.yaml
```

**Contenido de `data.yaml`:**

```yaml
path: ../datasets/helmet_vest_detection
train: train/images
val: valid/images
test: test/images  # opcional

nc: 3  # nÃºmero de clases (ajustar segÃºn tu dataset)
names: ['Person', 'Helmet', 'Vest']  # ajustar segÃºn las clases de tu dataset
```

---

### Paso 3: Crear Notebook de Entrenamiento

**OpciÃ³n A: Con Jupyter Notebook (Local)**

```powershell
# Desde la carpeta del proyecto
cd "C:\Users\LENOVO\OneDrive\Documentos\SISTEMASCORE\PROYECTOS\Safety-Vision-AI"

# Activar entorno (si no estÃ¡ activo)
C:/Users/LENOVO/OneDrive/Documentos/SISTEMASCORE/venv/Scripts/activate

# Iniciar Jupyter
jupyter notebook notebooks/
```

**OpciÃ³n B: Usar Google Colab (GPU Gratuita - Recomendado si no tienes GPU)**

1. Ve a: https://colab.research.google.com/
2. Nuevo Notebook
3. Cambiar a GPU: `Runtime > Change runtime type > T4 GPU`
4. Subir el dataset o conectar con Google Drive

---

### Paso 4: CÃ³digo para el Notebook de Entrenamiento

Crea un archivo `notebooks/2_yolov8_fine_tuning.ipynb` con este cÃ³digo:

```python
# ===== CELDA 1: Imports y Verificaciones =====
from ultralytics import YOLO
import torch
import os
from pathlib import Path

print(f"âœ… PyTorch version: {torch.__version__}")
print(f"âœ… CUDA available: {torch.cuda.is_available()}")
if torch.cuda.is_available():
    print(f"âœ… CUDA device: {torch.cuda.get_device_name(0)}")
else:
    print("âš ï¸ Running on CPU (esto serÃ¡ mÃ¡s lento)")

# ===== CELDA 2: Verificar Dataset =====
dataset_path = Path("../datasets/helmet_vest_detection")
data_yaml = dataset_path / "data.yaml"

if not data_yaml.exists():
    print("âŒ ERROR: No se encontrÃ³ data.yaml")
    print(f"Verifica que el dataset estÃ© en: {dataset_path}")
else:
    print(f"âœ… Dataset encontrado: {data_yaml}")
    
    # Contar imÃ¡genes
    train_images = list((dataset_path / "train" / "images").glob("*.jpg")) + \
                   list((dataset_path / "train" / "images").glob("*.png"))
    valid_images = list((dataset_path / "valid" / "images").glob("*.jpg")) + \
                   list((dataset_path / "valid" / "images").glob("*.png"))
    
    print(f"ğŸ“Š ImÃ¡genes de entrenamiento: {len(train_images)}")
    print(f"ğŸ“Š ImÃ¡genes de validaciÃ³n: {len(valid_images)}")

# ===== CELDA 3: Cargar Modelo Base =====
# Opciones:
# - yolov8n.pt (nano - mÃ¡s rÃ¡pido, menos preciso)
# - yolov8s.pt (small - balance)
# - yolov8m.pt (medium - mÃ¡s preciso, mÃ¡s lento)
# - yolov8l.pt (large - muy preciso, muy lento)

model = YOLO('yolov8n.pt')  # Empezamos con nano
print("âœ… Modelo base YOLOv8n cargado")

# ===== CELDA 4: Entrenar el Modelo =====
# IMPORTANTE: Ajusta estos parÃ¡metros segÃºn tu hardware
results = model.train(
    data=str(data_yaml),
    epochs=50,              # MÃ­nimo 30, ideal 50-100
    imgsz=640,              # TamaÃ±o de imagen (640 es estÃ¡ndar)
    batch=16,               # Si tienes error de memoria, reduce a 8, 4 o 2
    device=0,               # 0 = primera GPU, 'cpu' = CPU
    project='../models_assets',
    name='yolov8_helmet_vest',
    patience=10,            # Early stopping (detiene si no mejora en 10 epochs)
    save=True,
    plots=True,
    
    # Data Augmentation (ajustar si es necesario)
    hsv_h=0.015,            # Hue augmentation
    hsv_s=0.7,              # Saturation
    hsv_v=0.4,              # Value
    degrees=10.0,           # RotaciÃ³n Â±10 grados
    translate=0.1,          # TraslaciÃ³n
    scale=0.5,              # Escalado
    flipud=0.0,             # No voltear vertical
    fliplr=0.5,             # 50% voltear horizontal
    
    # Performance
    workers=8,              # Threads para cargar datos
    cache=False,            # True si tienes suficiente RAM
)

print("\n" + "="*50)
print("ğŸ‰ Â¡ENTRENAMIENTO COMPLETADO!")
print("="*50)

# ===== CELDA 5: Evaluar el Modelo =====
# Evaluar en el conjunto de validaciÃ³n
metrics = model.val()

print("\nğŸ“Š MÃ‰TRICAS DEL MODELO:")
print(f"mAP@0.5: {metrics.box.map50:.4f}")
print(f"mAP@0.5:0.95: {metrics.box.map:.4f}")
print(f"Precision: {metrics.box.mp:.4f}")
print(f"Recall: {metrics.box.mr:.4f}")

# ===== CELDA 6: Guardar el Mejor Modelo =====
import shutil

# El mejor modelo estÃ¡ en:
best_model_path = Path("../models_assets/yolov8_helmet_vest/weights/best.pt")

# Copiarlo a un lugar mÃ¡s accesible
if best_model_path.exists():
    destination = Path("../models_assets/yolov8_helmet_vest_best.pt")
    shutil.copy(best_model_path, destination)
    print(f"\nâœ… Mejor modelo guardado en: {destination}")
    print(f"ğŸ“ TamaÃ±o del archivo: {destination.stat().st_size / (1024*1024):.2f} MB")
else:
    print("âŒ No se encontrÃ³ el modelo entrenado")

# ===== CELDA 7: Probar el Modelo (Opcional) =====
# Probar en una imagen del conjunto de validaciÃ³n
if valid_images:
    test_image = str(valid_images[0])
    
    # Cargar el mejor modelo
    best_model = YOLO(str(destination))
    
    # Hacer predicciÃ³n
    results = best_model(test_image)
    
    # Mostrar resultado
    import matplotlib.pyplot as plt
    from PIL import Image
    
    # Dibujar predicciones
    annotated = results[0].plot()
    
    plt.figure(figsize=(12, 8))
    plt.imshow(annotated[..., ::-1])  # BGR to RGB
    plt.axis('off')
    plt.title('PredicciÃ³n del Modelo')
    plt.show()
    
    print(f"\nğŸ¯ Detecciones en la imagen de prueba:")
    for box in results[0].boxes:
        cls = int(box.cls[0])
        conf = float(box.conf[0])
        name = results[0].names[cls]
        print(f"  - {name}: {conf:.2f}")
```

---

### Paso 5: Ejecutar el Entrenamiento

**Si estÃ¡s en local:**

```powershell
# Ya deberÃ­as tener Jupyter abierto
# Ejecuta cada celda del notebook una por una
# CTRL + Enter para ejecutar una celda
# Shift + Enter para ejecutar y pasar a la siguiente
```

**Si estÃ¡s en Colab:**

1. Instala Ultralytics primero:
   ```python
   !pip install ultralytics
   ```

2. Sube tu dataset o monta Google Drive:
   ```python
   from google.colab import drive
   drive.mount('/content/drive')
   ```

3. Ejecuta las celdas del notebook

---

## â±ï¸ Tiempo Estimado

- **Descarga de dataset:** 10-15 minutos
- **Setup del notebook:** 5 minutos
- **Entrenamiento:**
  - Con GPU (NVIDIA): 30-60 minutos (50 epochs)
  - Con CPU: 3-6 horas (no recomendado para 50 epochs)
  - Google Colab (T4 GPU): 40-80 minutos

---

## ğŸ“Š MÃ©tricas Esperadas (Objetivos)

| MÃ©trica | MÃ­nimo Aceptable | Ideal |
|---------|------------------|-------|
| mAP@0.5 | > 0.75 | > 0.85 |
| mAP@0.5:0.95 | > 0.50 | > 0.65 |
| Precision | > 0.80 | > 0.90 |
| Recall | > 0.75 | > 0.85 |

Si tus mÃ©tricas estÃ¡n por debajo del mÃ­nimo:
- Entrena por mÃ¡s epochs (100+)
- Usa un dataset mÃ¡s grande
- Prueba con YOLOv8s o YOLOv8m (modelos mÃ¡s grandes)

---

## ğŸ†˜ Troubleshooting ComÃºn

### Error: "CUDA out of memory"
**SoluciÃ³n:** Reduce el `batch` size:
```python
batch=8  # en lugar de 16
# O incluso batch=4 o batch=2
```

### Error: "Dataset not found"
**SoluciÃ³n:** Verifica la ruta en `data.yaml` y que las carpetas existan

### Entrenamiento muy lento en CPU
**SoluciÃ³n:** Usa Google Colab con GPU gratuita

### El modelo no detecta bien
**SoluciÃ³n:** 
- Entrena por mÃ¡s epochs
- Aumenta el dataset
- Verifica que las anotaciones sean correctas

---

## âœ… Criterio de Ã‰xito de FASE 1

Marca estos Ã­tems cuando los completes:

- [ ] Dataset descargado y verificado
- [ ] Notebook de entrenamiento creado
- [ ] Entrenamiento completado (min 30 epochs)
- [ ] Modelo guardado en `models_assets/yolov8_helmet_vest_best.pt`
- [ ] mAP@0.5 > 0.75
- [ ] Predicciones visuales verificadas

---

## ğŸ“ Siguiente Fase

Una vez completada la FASE 1, continuaremos con:

**FASE 2: Pipeline de Inferencia BÃ¡sico**
- Captura de video
- DetecciÃ³n en tiempo real
- VisualizaciÃ³n con bounding boxes

---

## ğŸ”— Links Ãštiles

- **Tu Repositorio:** https://github.com/leonardobaca7/safety-vision-ai
- **Roboflow Universe:** https://universe.roboflow.com/
- **Google Colab:** https://colab.research.google.com/
- **Ultralytics Docs:** https://docs.ultralytics.com/
- **FASE_1_GUIA.md completa:** Consulta para mÃ¡s detalles

---

## ğŸ’¡ Consejos Finales

1. **Commitea frecuentemente:**
   ```bash
   git add .
   git commit -m "feat: completed model training with mAP 0.85"
   git push
   ```

2. **Documenta tus resultados:** Anota las mÃ©tricas en el README

3. **No te rindas:** Si el primer entrenamiento no es perfecto, ajusta hiperparÃ¡metros e intenta de nuevo

4. **Pide ayuda:** Si te atascas, no dudes en preguntar

---

Â¡Mucho Ã©xito con la FASE 1! ğŸš€ğŸ”¥

**Leonardo, a darle con todo! ğŸ’ª**
